"""
Text-to-Speech service using OpenAI gpt-4o-mini-tts.

Provides emotionally aware speech synthesis for Scene Partner rehearsal.
TTS instructions are auto-generated by the scene partner LLM from scene context.

Audio is cached by (text + voice + instructions) hash to avoid redundant API calls.
"""

import hashlib
import logging
from collections import OrderedDict
from typing import Iterator, Optional

from openai import OpenAI

from app.core.config import settings

logger = logging.getLogger(__name__)

# In-memory LRU cache: hash → audio bytes
# 200 entries × ~50KB avg = ~10MB max memory
_TTS_CACHE: OrderedDict[str, bytes] = OrderedDict()
_TTS_CACHE_MAX = 200

# Voice profiles for character casting
VOICE_PROFILES = {
    # Masculine-presenting
    "ash": {"gender_affinity": "male", "quality": "warm, deep", "age": "adult"},
    "echo": {"gender_affinity": "male", "quality": "smooth, neutral", "age": "young_adult"},
    "fable": {"gender_affinity": "male", "quality": "expressive, British", "age": "adult"},
    "onyx": {"gender_affinity": "male", "quality": "deep, authoritative", "age": "mature"},
    # Feminine-presenting
    "coral": {"gender_affinity": "female", "quality": "warm, expressive", "age": "adult"},
    "nova": {"gender_affinity": "female", "quality": "bright, energetic", "age": "young_adult"},
    "sage": {"gender_affinity": "female", "quality": "calm, measured", "age": "adult"},
    "shimmer": {"gender_affinity": "female", "quality": "light, youthful", "age": "young_adult"},
    # Neutral
    "alloy": {"gender_affinity": "neutral", "quality": "balanced, clear", "age": "adult"},
    "ballad": {"gender_affinity": "neutral", "quality": "melodic, gentle", "age": "adult"},
}

DEFAULT_VOICE_MALE = "ash"
DEFAULT_VOICE_FEMALE = "coral"
DEFAULT_VOICE_NEUTRAL = "alloy"


def get_voice_for_character(
    character_name: str,
    character_gender: Optional[str] = None,
    scene_tone: Optional[str] = None,
) -> str:
    """
    Select an OpenAI TTS voice for a character.

    Deterministic: same character gender + tone always returns the same voice.
    """
    gender = (character_gender or "").lower().strip()
    tone = (scene_tone or "").lower().strip()

    if gender in ("male", "m"):
        if tone in ("comedic", "light", "playful"):
            return "echo"
        if tone in ("dramatic", "intense", "tragic"):
            return "onyx"
        return DEFAULT_VOICE_MALE
    elif gender in ("female", "f"):
        if tone in ("comedic", "light", "playful"):
            return "shimmer"
        if tone in ("dramatic", "intense", "tragic"):
            return "sage"
        return DEFAULT_VOICE_FEMALE
    else:
        return DEFAULT_VOICE_NEUTRAL


def _cache_key(text: str, voice: str, instructions: str, fmt: str) -> str:
    """Deterministic hash for a TTS request."""
    raw = f"{text}|{voice}|{instructions}|{fmt}"
    return hashlib.md5(raw.encode()).hexdigest()


class TTSService:
    """OpenAI gpt-4o-mini-tts wrapper for Scene Partner."""

    def __init__(self) -> None:
        api_key = settings.openai_api_key
        if not api_key:
            raise ValueError("OPENAI_API_KEY is required for TTS service")
        self.client = OpenAI(api_key=api_key)

    def synthesize_speech(
        self,
        text: str,
        voice: str = "coral",
        instructions: str = "",
        response_format: str = "mp3",
    ) -> bytes:
        """Synthesize speech and return audio bytes (cached)."""
        key = _cache_key(text, voice, instructions, response_format)

        # Check in-memory cache
        if key in _TTS_CACHE:
            logger.debug("TTS cache hit: %s", key[:8])
            _TTS_CACHE.move_to_end(key)
            return _TTS_CACHE[key]

        # Generate via OpenAI
        kwargs: dict = {
            "model": "gpt-4o-mini-tts",
            "voice": voice,
            "input": text,
            "response_format": response_format,
        }
        if instructions:
            kwargs["instructions"] = instructions

        response = self.client.audio.speech.create(**kwargs)
        audio = response.content

        # Store in LRU cache
        _TTS_CACHE[key] = audio
        _TTS_CACHE.move_to_end(key)
        if len(_TTS_CACHE) > _TTS_CACHE_MAX:
            _TTS_CACHE.popitem(last=False)
        logger.debug("TTS cached: %s (%d bytes)", key[:8], len(audio))

        return audio

    def synthesize_speech_streaming(
        self,
        text: str,
        voice: str = "coral",
        instructions: str = "",
        response_format: str = "mp3",
        chunk_size: int = 4096,
    ) -> Iterator[bytes]:
        """Synthesize speech and yield audio chunks for streaming."""
        audio_bytes = self.synthesize_speech(
            text=text,
            voice=voice,
            instructions=instructions,
            response_format=response_format,
        )
        for i in range(0, len(audio_bytes), chunk_size):
            yield audio_bytes[i : i + chunk_size]
